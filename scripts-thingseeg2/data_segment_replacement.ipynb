{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import scipy as sp\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr,binom,linregress\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_corr_all(ground_truth, predictions):\n",
    "    r = np.corrcoef(ground_truth, predictions)#cosine_similarity(ground_truth, predictions)#\n",
    "    r = r[:len(ground_truth), len(ground_truth):]  # rows: groundtruth, columns: predicitons\n",
    "    #print(r.shape)\n",
    "    # congruent pairs are on diagonal\n",
    "    congruents = np.diag(r)\n",
    "    #print(congruents)\n",
    "    \n",
    "    # for each column (predicition) we should count the number of rows (groundtruth) that the value is lower than the congruent (e.g. success).\n",
    "    success = r < congruents\n",
    "    success_cnt = np.sum(success, 0)\n",
    "    \n",
    "    # note: diagonal of 'success' is always zero so we can discard it. That's why we divide by len-1\n",
    "    perf = np.mean(success_cnt) / (len(ground_truth)-1)\n",
    "    p = 1 - binom.cdf(perf*len(ground_truth)*(len(ground_truth)-1), len(ground_truth)*(len(ground_truth)-1), 0.5)\n",
    "    \n",
    "    return perf, p\n",
    "\n",
    "def pairwise_corr_individuals(ground_truth, predictions):\n",
    "    r = np.corrcoef(ground_truth, predictions)#cosine_similarity(ground_truth, predictions)#\n",
    "    r = r[:len(ground_truth), len(ground_truth):]  # rows: groundtruth, columns: predicitons\n",
    "    #print(r.shape)\n",
    "    # congruent pairs are on diagonal\n",
    "    congruents = np.diag(r)\n",
    "    #print(congruents)\n",
    "    \n",
    "    # for each column (predicition) we should count the number of rows (groundtruth) that the value is lower than the congruent (e.g. success).\n",
    "    success = r < congruents\n",
    "    success_cnt = np.sum(success, 0)\n",
    "    \n",
    "    # note: diagonal of 'success' is always zero so we can discard it. That's why we divide by len-1\n",
    "    perf = success_cnt / (len(ground_truth)-1)\n",
    "    # p = 1 - binom.cdf(perf*len(ground_truth)*(len(ground_truth)-1), len(ground_truth)*(len(ground_truth)-1), 0.5)\n",
    "    \n",
    "    return perf\n",
    "\n",
    "\n",
    "net_list = [\n",
    "    ('inceptionv3','avgpool'),\n",
    "    ('clip','final'),\n",
    "    ('alexnet',2),\n",
    "    ('alexnet',5),\n",
    "    ('efficientnet','avgpool'),\n",
    "    ('swav','avgpool')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inceptionv3 avgpool\n",
      "clip final\n",
      "alexnet 2\n",
      "alexnet 5\n",
      "efficientnet avgpool\n",
      "distance:  0.9121800053943298\n",
      "swav avgpool\n",
      "distance:  0.5758596473932266\n"
     ]
    }
   ],
   "source": [
    "num_test = 200\n",
    "test_dir = 'cache/thingseeg2_preproc/eval_features/test_images'\n",
    "feats_dir = 'cache/thingseeg2_preproc/eval_features/subj1_preproc_800ms'\n",
    "distance_fn = sp.spatial.distance.correlation\n",
    "pairwise_corrs = []\n",
    "for (net_name,layer) in net_list:\n",
    "    file_name = '{}/{}_{}.npy'.format(test_dir,net_name,layer)\n",
    "    gt_feat = np.load(file_name)\n",
    "    \n",
    "    file_name = '{}/{}_{}.npy'.format(feats_dir,net_name,layer)\n",
    "    eval_feat = np.load(file_name)\n",
    "    \n",
    "    gt_feat = gt_feat.reshape((len(gt_feat),-1))\n",
    "    eval_feat = eval_feat.reshape((len(eval_feat),-1))\n",
    "\n",
    "    print(net_name,layer)\n",
    "    if net_name in ['efficientnet','swav']:\n",
    "        print('distance: ',np.array([distance_fn(gt_feat[i],eval_feat[i]) for i in range(num_test)]).mean())\n",
    "    else:\n",
    "        # pairwise_corrs.append(pairwise_corr_all(gt_feat[:num_test],eval_feat[:num_test])[0])\n",
    "        pairwise_corrs.append(pairwise_corr_individuals(gt_feat[:num_test],eval_feat[:num_test]))\n",
    "        # print('pairwise corr: ',pairwise_corrs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_inds = np.argsort(pairwise_corrs[0])[::-1]\n",
    "clip_inds = np.argsort(pairwise_corrs[1])[::-1]\n",
    "alexnet2_inds = np.argsort(pairwise_corrs[2])[::-1]\n",
    "alexnet5_inds = np.argsort(pairwise_corrs[3])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16540, 17, 80) (200, 17, 80)\n"
     ]
    }
   ],
   "source": [
    "# train_path = 'data/things-eeg2_preproc/sub01/train_thingseeg2_avg_800ms.npy'\n",
    "train_path = 'data/things-eeg2_preproc/train_thingseeg2_avg_800ms.npy'\n",
    "train_eeg = np.load(train_path, mmap_mode='r')\n",
    "# train_eeg_flattened = train_eeg.reshape(train_eeg.shape[0], -1)\n",
    "# test_path = 'data/things-eeg2_preproc/sub01/test_thingseeg2_avg_800ms.npy'\n",
    "test_path = 'data/things-eeg2_preproc/test_thingseeg2_avg_800ms.npy'\n",
    "test_eeg = np.load(test_path, mmap_mode='r')\n",
    "test_eeg = test_eeg[clip_inds]\n",
    "# test_eeg_flattened = test_eeg.reshape(test_eeg.shape[0], -1)\n",
    "print(train_eeg.shape, test_eeg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eeg_0 = test_eeg[0]\n",
    "test_eeg_4 = test_eeg[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 5\n",
    "stride = 1\n",
    "n_examples = 80 - time_window + 1\n",
    "synthetic_eeg_0to4 = np.zeros((n_examples, 17, 80))\n",
    "synthetic_eeg_4to0 = np.zeros((n_examples, 17, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_example in range(n_examples - 1):\n",
    "    synthetic_eeg_0to4[i_example] = test_eeg_4\n",
    "    synthetic_eeg_4to0[i_example] = test_eeg_0\n",
    "    start = i_example * stride\n",
    "    end = start + time_window\n",
    "    synthetic_eeg_0to4[i_example,:, start:end] = test_eeg_0[:, start:end]\n",
    "    synthetic_eeg_4to0[i_example,:, start:end] = test_eeg_4[:, start:end]\n",
    "synthetic_eeg_0to4[-1] = test_eeg_4\n",
    "synthetic_eeg_4to0[-1] = test_eeg_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'cache/thingseeg2_synthetic/'\n",
    "if not os.path.exists(dir):\n",
    "   os.makedirs(dir)\n",
    "np.save(dir + 'sub01_0to4__5_1__800ms.npy', synthetic_eeg_0to4)\n",
    "np.save(dir + 'sub01_4to0__5_1__800ms.npy', synthetic_eeg_4to0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eeg_20 = test_eeg[20]\n",
    "test_eeg_37 = test_eeg[37]\n",
    "\n",
    "test_eeg_36 = test_eeg[36]\n",
    "test_eeg_90 = test_eeg[90]\n",
    "\n",
    "test_eeg_28 = test_eeg[28]\n",
    "test_eeg_68 = test_eeg[68]\n",
    "\n",
    "test_eeg_34 = test_eeg[34]\n",
    "test_eeg_127 = test_eeg[127]\n",
    "\n",
    "test_eeg_9 = test_eeg[9]\n",
    "test_eeg_35 = test_eeg[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 5\n",
    "stride = 1\n",
    "n_examples = 80 - time_window + 1\n",
    "synthetic_eeg_20to37 = np.zeros((n_examples, 17, 80))\n",
    "synthetic_eeg_37to20 = np.zeros((n_examples, 17, 80))\n",
    "\n",
    "for i_example in range(n_examples - 1):\n",
    "    synthetic_eeg_20to37[i_example] = test_eeg_37\n",
    "    synthetic_eeg_37to20[i_example] = test_eeg_20\n",
    "    start = i_example * stride\n",
    "    end = start + time_window\n",
    "    synthetic_eeg_20to37[i_example,:, start:end] = test_eeg_20[:, start:end]\n",
    "    synthetic_eeg_37to20[i_example,:, start:end] = test_eeg_37[:, start:end]\n",
    "synthetic_eeg_20to37[-1] = test_eeg_37\n",
    "synthetic_eeg_37to20[-1] = test_eeg_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 5\n",
    "stride = 1\n",
    "n_examples = 80 - time_window + 1\n",
    "synthetic_eeg_36to90 = np.zeros((n_examples, 17, 80))\n",
    "synthetic_eeg_90to36 = np.zeros((n_examples, 17, 80))\n",
    "\n",
    "for i_example in range(n_examples - 1):\n",
    "    synthetic_eeg_36to90[i_example] = test_eeg_90\n",
    "    synthetic_eeg_90to36[i_example] = test_eeg_36\n",
    "    start = i_example * stride\n",
    "    end = start + time_window\n",
    "    synthetic_eeg_36to90[i_example,:, start:end] = test_eeg_36[:, start:end]\n",
    "    synthetic_eeg_90to36[i_example,:, start:end] = test_eeg_90[:, start:end]\n",
    "synthetic_eeg_36to90[-1] = test_eeg_90\n",
    "synthetic_eeg_90to36[-1] = test_eeg_36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 5\n",
    "stride = 1\n",
    "n_examples = 80 - time_window + 1\n",
    "synthetic_eeg_28to68 = np.zeros((n_examples, 17, 80))\n",
    "synthetic_eeg_68to28 = np.zeros((n_examples, 17, 80))\n",
    "\n",
    "for i_example in range(n_examples - 1):\n",
    "    synthetic_eeg_28to68[i_example] = test_eeg_68\n",
    "    synthetic_eeg_68to28[i_example] = test_eeg_28\n",
    "    start = i_example * stride\n",
    "    end = start + time_window\n",
    "    synthetic_eeg_28to68[i_example,:, start:end] = test_eeg_28[:, start:end]\n",
    "    synthetic_eeg_68to28[i_example,:, start:end] = test_eeg_68[:, start:end]\n",
    "synthetic_eeg_28to68[-1] = test_eeg_68\n",
    "synthetic_eeg_68to28[-1] = test_eeg_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 5\n",
    "stride = 1\n",
    "n_examples = 80 - time_window + 1\n",
    "synthetic_eeg_34to127 = np.zeros((n_examples, 17, 80))\n",
    "synthetic_eeg_127to34 = np.zeros((n_examples, 17, 80))\n",
    "\n",
    "for i_example in range(n_examples - 1):\n",
    "    synthetic_eeg_34to127[i_example] = test_eeg_127\n",
    "    synthetic_eeg_127to34[i_example] = test_eeg_34\n",
    "    start = i_example * stride\n",
    "    end = start + time_window\n",
    "    synthetic_eeg_34to127[i_example,:, start:end] = test_eeg_34[:, start:end]\n",
    "    synthetic_eeg_127to34[i_example,:, start:end] = test_eeg_127[:, start:end]\n",
    "synthetic_eeg_34to127[-1] = test_eeg_127\n",
    "synthetic_eeg_127to34[-1] = test_eeg_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 5\n",
    "stride = 1\n",
    "n_examples = 80 - time_window + 1\n",
    "synthetic_eeg_9to35 = np.zeros((n_examples, 17, 80))\n",
    "synthetic_eeg_35to9 = np.zeros((n_examples, 17, 80))\n",
    "\n",
    "for i_example in range(n_examples - 1):\n",
    "    synthetic_eeg_9to35[i_example] = test_eeg_35\n",
    "    synthetic_eeg_35to9[i_example] = test_eeg_9\n",
    "    start = i_example * stride\n",
    "    end = start + time_window\n",
    "    synthetic_eeg_9to35[i_example,:, start:end] = test_eeg_9[:, start:end]\n",
    "    synthetic_eeg_35to9[i_example,:, start:end] = test_eeg_35[:, start:end]\n",
    "synthetic_eeg_9to35[-1] = test_eeg_35\n",
    "synthetic_eeg_35to9[-1] = test_eeg_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'cache/thingseeg2_synthetic/'\n",
    "if not os.path.exists(dir):\n",
    "   os.makedirs(dir)\n",
    "np.save(dir + 'sub01_20to37__5_1__800ms.npy', synthetic_eeg_20to37)\n",
    "np.save(dir + 'sub01_37to20__5_1__800ms.npy', synthetic_eeg_37to20)\n",
    "np.save(dir + 'sub01_36to90__5_1__800ms.npy', synthetic_eeg_36to90)\n",
    "np.save(dir + 'sub01_90to36__5_1__800ms.npy', synthetic_eeg_90to36)\n",
    "np.save(dir + 'sub01_28to68__5_1__800ms.npy', synthetic_eeg_28to68)\n",
    "np.save(dir + 'sub01_68to28__5_1__800ms.npy', synthetic_eeg_68to28)\n",
    "np.save(dir + 'sub01_34to127__5_1__800ms.npy', synthetic_eeg_34to127)\n",
    "np.save(dir + 'sub01_127to34__5_1__800ms.npy', synthetic_eeg_127to34)\n",
    "np.save(dir + 'sub01_9to35__5_1__800ms.npy', synthetic_eeg_9to35)\n",
    "np.save(dir + 'sub01_35to9__5_1__800ms.npy', synthetic_eeg_35to9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
