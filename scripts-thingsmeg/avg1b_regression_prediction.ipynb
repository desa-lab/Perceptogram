{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn.linear_model as skl\n",
    "import os\n",
    "from scipy.spatial.distance import correlation\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict VDVAE Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/regression_weights/BIGMEG1/thingsmeg_regress_autokl1b_weights_sub-BIGMEG1.pkl',\"rb\") as f:\n",
    "    datadict = pickle.load(f)\n",
    "    reg_w = datadict['weight']\n",
    "    reg_b = datadict['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = skl.Ridge(alpha=50000, max_iter=10000, fit_intercept=True)\n",
    "reg.coef_ = reg_w\n",
    "reg.intercept_ = reg_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_epochs = np.load('cache/processed_data/BIGMEG1/test_avg_thingsmeg_sub-BIGMEG1.npy')\n",
    "averaged_epochs = averaged_epochs.reshape(averaged_epochs.shape[0], -1) # concatenate all time points\n",
    "train_latents = np.load('cache/extracted_embeddings/BIGMEG1/train_autokl1b_sub-BIGMEG1.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_latent = reg.predict(averaged_epochs)\n",
    "std_norm_test_latent = (pred_test_latent - np.mean(pred_test_latent,axis=0)) / np.std(pred_test_latent,axis=0)\n",
    "pred_latents = std_norm_test_latent * np.std(train_latents,axis=0) + np.mean(train_latents,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'BIGMEG1'\n",
    "save_dir = 'cache/predicted_embeddings/' + subject + '/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "np.save(save_dir + f'avg_thingsmeg_regress_autokl1b_sub-{subject}.npy', pred_latents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run `vdvae_reconstruct_images1b.py` or `vdvae_reconstruct_images.py` after this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict CLIP-Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/regression_weights/BIGMEG1/thingsmeg_regress_cliptext1bcategoryalltokens_weights_sub-BIGMEG1.pkl',\"rb\") as f:\n",
    "    datadict = pickle.load(f)\n",
    "    reg_w = datadict['weight']\n",
    "    reg_b = datadict['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_epochs = np.load('cache/processed_data/BIGMEG1/test_avg_thingsmeg_sub-BIGMEG1.npy')\n",
    "averaged_epochs = averaged_epochs.reshape(averaged_epochs.shape[0], -1) # concatenate all time points\n",
    "train_clip = np.load('cache/extracted_embeddings/BIGMEG1/train_cliptext1bcategory_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "# test_clip = np.load('cache/extracted_embeddings/BIGMEG1/test_cliptext1bcategory_sub-BIGMEG1.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:45<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "num_embed = 77\n",
    "pred_clip = np.zeros((averaged_epochs.shape[0], num_embed, 768))\n",
    "for i in tqdm(range(num_embed), total=num_embed):\n",
    "    reg = skl.Ridge(alpha=100000, max_iter=50000, fit_intercept=True) # old alpha=100000, optimal alpha=1200000\n",
    "\n",
    "    reg.coef_ = reg_w[i]\n",
    "    reg.intercept_ = reg_b[i]\n",
    "    \n",
    "    pred_test_latent = reg.predict(averaged_epochs)\n",
    "    std_norm_test_latent = (pred_test_latent - np.mean(pred_test_latent,axis=0)) / np.std(pred_test_latent,axis=0)\n",
    "    pred_clip[:,i] = std_norm_test_latent * np.std(train_clip[:,i],axis=0) + np.mean(train_clip[:,i],axis=0)\n",
    "\n",
    "    # # Compute the Euclidean distances\n",
    "    # euclidean_distances = np.array([np.linalg.norm(u - v) for u, v in zip(pred_clip[:,i], test_clip[:,i])])\n",
    "    # correlation_distances = np.array([correlation(u, v) for u, v in zip(pred_clip[:,i], test_clip[:,i])])\n",
    "    # # Compute the average Euclidean distance\n",
    "    # average_euclidean_distance = euclidean_distances.mean()\n",
    "    # correlations = (1 - correlation_distances).mean()\n",
    "\n",
    "    # print(i,reg.score(averaged_epochs,test_clip[:,i]), average_euclidean_distance, correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'BIGMEG1'\n",
    "save_dir = 'cache/predicted_embeddings/' + subject + '/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "np.save(save_dir + f'avg_thingsmeg_regress_cliptext1bcategoryalltokens_sub-{subject}.npy', pred_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict CLIP-Vision Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/regression_weights/BIGMEG1/thingsmeg_regress_clipvision1b_weights_sub-BIGMEG1_precomputed.pkl',\"rb\") as f:\n",
    "    datadict = pickle.load(f)\n",
    "    reg_w = datadict['weight']\n",
    "    reg_b = datadict['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_epochs = np.load('cache/processed_data/BIGMEG1/test_avg_thingsmeg_sub-BIGMEG1.npy')\n",
    "averaged_epochs = averaged_epochs.reshape(averaged_epochs.shape[0], -1) # concatenate all time points\n",
    "train_clip = np.load('cache/extracted_embeddings/BIGMEG1/train_clipvision1b_sub-BIGMEG1.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/257 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "num_embed = 257\n",
    "pred_clip = np.zeros((averaged_epochs.shape[0], num_embed, 768))\n",
    "for i in tqdm(range(num_embed), total=num_embed):\n",
    "    reg = skl.Ridge(alpha=60000, max_iter=50000, fit_intercept=True) # old alpha=60000, optimal alpha=300000\n",
    "    \n",
    "    reg.coef_ = reg_w[i]\n",
    "    reg.intercept_ = reg_b[i]\n",
    "    \n",
    "    pred_test_latent = reg.predict(averaged_epochs)\n",
    "    std_norm_test_latent = (pred_test_latent - np.mean(pred_test_latent,axis=0)) / np.std(pred_test_latent,axis=0)\n",
    "    pred_clip[:,i] = std_norm_test_latent * np.std(train_clip[:,i],axis=0) + np.mean(train_clip[:,i],axis=0)\n",
    "\n",
    "    # # Compute the Euclidean distances\n",
    "    # euclidean_distances = np.array([np.linalg.norm(u - v) for u, v in zip(pred_clip[:,i], test_clip[:,i])])\n",
    "    # correlation_distances = np.array([correlation(u, v) for u, v in zip(pred_clip[:,i], test_clip[:,i])])\n",
    "    # # Compute the average Euclidean distance\n",
    "    # average_euclidean_distance = euclidean_distances.mean()\n",
    "    # correlations = (1 - correlation_distances).mean()\n",
    "    \n",
    "    # print(i,reg.score(test_fmri,test_clip[:,i]), average_euclidean_distance, correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'BIGMEG1'\n",
    "save_dir = 'cache/predicted_embeddings/' + subject + '/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "np.save(save_dir + f'avg_thingsmeg_regress_clipvision1b_sub-{subject}_precomputed.npy', pred_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
